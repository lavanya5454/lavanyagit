{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP0G5udNWgy24fF+6DJbWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lavanya5454/lavanyagit/blob/main/Featured_engineering%20and%20model%20validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Rjkr0RehxLVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bae60e-5622-41a3-8091-2b334f1cb7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1411.88704064   17.60537322   53.10803984 2175.56527292  127.66934333\n",
            "    5.39268155  181.30368904]\n"
          ]
        }
      ],
      "source": [
        "from pandas import read_csv\n",
        "from numpy import set_printoptions\n",
        "from sklearn. feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "filename = '/content/pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas','pres', 'skin','rest','pedi','age','class']\n",
        "\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "x=array[:,0:7]\n",
        "y=array[:,7]\n",
        "test=SelectKBest(score_func=chi2,k=5)\n",
        "fit=test.fit(x,y)\n",
        "#set_printoptions(precision=4)\n",
        "print(fit.scores_)\n",
        "features=fit.transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=fit.scores_\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVH1S5bCzTc0",
        "outputId": "4f3d8929-5dcf-4675-8b53-e424588e3588"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1411.88704064,   17.60537322,   53.10803984, 2175.56527292,\n",
              "        127.66934333,    5.39268155,  181.30368904])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recursive Feature Elimination**"
      ],
      "metadata": {
        "id": "bAX9jHb70u_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "filename = '/content/pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas','pres', 'skin','rest','pedi','age','class']\n",
        "\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "x=array[:,0:7]\n",
        "y=array[:,7]\n",
        "model=LogisticRegression(max_iter=400)\n",
        "rfe=RFE(model)\n",
        "fit=rfe.fit(x,y)"
      ],
      "metadata": {
        "id": "QnpluqGeyq02"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit.support_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN12kiwdzGJb",
        "outputId": "26712ac2-7cee-4a6b-9cd3-aea5479b69f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, False,  True,  True, False])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit.ranking_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSgZXKdX1rk4",
        "outputId": "8e976832-800d-4a04-dbce-4127262239ab"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 5, 4, 1, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "25rST5er23fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "filename = '/content/pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas','pres', 'skin','rest','pedi','age','class']\n",
        "dataframe = read_csv(filename, names=names)\n",
        "array = dataframe.values\n",
        "x=array[:,0:7]\n",
        "y=array[:,7]\n",
        "model=DecisionTreeClassifier()\n",
        "model.fit(x,y)\n",
        "print(model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssn5cxAJ1uqi",
        "outputId": "4e445150-d552-414e-9a17-d46c68f1c371"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31323702 0.11091331 0.05771393 0.04736705 0.21323377 0.12970855\n",
            " 0.12782638]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "dataframe\n",
        "x=dataframe.iloc[:,0:7]\n",
        "y=dataframe.iloc[:,7]\n",
        "model=SelectKBest(score_func=chi2)\n",
        "model.fit(x,y)\n",
        "model.scores_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyJWmUMn2jbS",
        "outputId": "0781d82b-92d5-4313-a463-5d6136223bab"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_selection/_univariate_selection.py:776: UserWarning: k=10 is greater than n_features=7. All the features will be returned.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1411.88704064,   17.60537322,   53.10803984, 2175.56527292,\n",
              "        127.66934333,    5.39268155,  181.30368904])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model validation**"
      ],
      "metadata": {
        "id": "VkEdJQ5wMk1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this method when we have large data more than data in thousands"
      ],
      "metadata": {
        "id": "UNkj3ufTwPb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "dataframe\n",
        "x=dataframe.iloc[:,0:7]\n",
        "y=dataframe.iloc[:,7]\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "ypred=model.predict(x_test)\n",
        "model.score(x_test,y_test)"
      ],
      "metadata": {
        "id": "sEeBNAoZ5ysD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512a8d60-c072-4921-c8f5-748612ba508f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8008658008658008"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt8ZR8bGNnB4",
        "outputId": "231e98e5-3ef9-4d89-b3b3-948ce1b374bd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7690875232774674"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Evaluate using cross validation\n",
        "\n",
        "\n",
        "this method when data is in thousands"
      ],
      "metadata": {
        "id": "a2etTXpnrNJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "filename=read_csv('/content/pima-indians-diabetes.data.csv',names=names)\n",
        "names = ['preg', 'plas','pres', 'skin','rest','pedi','age','classe']\n",
        "x=filename.drop(labels=['classe'],axis=1)\n",
        "y=filename.classe\n",
        "seed=7\n",
        "kfold=KFold(n_splits=5)\n",
        "model=LogisticRegression(max_iter=400)\n",
        "results=cross_val_score(model,x,y,cv=kfold)\n",
        "results"
      ],
      "metadata": {
        "id": "bA9l6Pm3Ns6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2736bb52-e4f1-4ef9-9a54-d1a2e61a28b6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.79220779, 0.72727273, 0.75324675, 0.81699346, 0.76470588])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Evaluate using leave one out cross validation"
      ],
      "metadata": {
        "id": "2i_wg5j4vrVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this methods when data is in 100's\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "filename=read_csv('/content/pima-indians-diabetes.data.csv',names=names)\n",
        "names = ['preg', 'plas','pres', 'skin','rest','pedi','age','classe']\n",
        "x=filename.drop(labels=['classe'],axis=1)\n",
        "y=filename.classe\n",
        "locv=LeaveOneOut()\n",
        "model=LogisticRegression(max_iter=300)\n",
        "results=cross_val_score(model,x,y,cv=locv)\n"
      ],
      "metadata": {
        "id": "mBR9Gvckt3L7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8KsgI-qvfoC",
        "outputId": "6152ccc0-33d0-4d55-8f26-4bc4897bed25"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "       1., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1R7EUhQCvnuu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}